services:
  mysql:
    image: mysql:8.0.39
    container_name: mysql_8_0
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: test_db
      MYSQL_USER: thangvo
      MYSQL_PASSWORD: thangvo123
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      - app-network

  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./Spark/Scripts:/opt/spark/scripts  # Changed from /opt/bitnami/spark/scripts
    networks:
      - app-network

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./Spark/Scripts:/opt/spark/scripts  # Added volume mount to worker
    depends_on:
      - spark-master
    networks:
      - app-network

  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"  # Add port mapping
    volumes:
      - postgres-data:/var/lib/postgresql/data  # Add persistent volume
    networks:
      - app-network

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./Spark/Scripts:/opt/spark/scripts
      - ./airflow/config:/opt/airflow
    ports:
      - "8081:8080"
    command: webserver
    networks:
      - app-network
    depends_on:
      - postgres

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - _AIRFLOW_DB_UPGRADE=true
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./Spark/Scripts:/opt/spark/scripts
      - ./airflow/config:/opt/airflow
    command: scheduler
    networks:
      - app-network
    depends_on:
      - postgres

volumes:
  mysql-data:
    driver: local
  spark-data:
    driver: local
  postgres-data:   
    driver: local

networks:
  app-network:
    driver: bridge
